{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "from skimage.io import imread_collection, imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "filepath='../every.resn50.hdf5'\n",
    "img_width, img_height = 243, 243\n",
    "\n",
    "train_data_dir = '../dataset/training_set/smo'\n",
    "validation_data_dir = '../dataset/test_set/smo'\n",
    "\n",
    "nb_train_samples = 5106\n",
    "nb_validation_samples = 1355\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        \n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', pooling='avg'\n",
    "                       ,input_tensor=Input((img_width, img_height, 3)))\n",
    "    # -  https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py\n",
    "    # -  https://keras.io/zh/layers/core/\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    #x = Flatten()(base_model.output)#将输入展平。不影响批量大小。\n",
    "    x = Dropout(0.5)(base_model.output) # this line shoule  be the first line!  // 0.5  is better then 0.2\n",
    "    x = Dense(2, activation='softmax', name='fc2')(base_model.output) #加入神經元(隱藏層) 2,foftmax\n",
    "\n",
    "    model = Model(base_model.input, x)\n",
    "  \n",
    "    for layer in model.layers[140:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "\n",
    "    train_path ='../dataset/training_set/smo'\n",
    "    test_path = '../dataset/test_set/smo'\n",
    "\n",
    "    ''' \n",
    "    Optimizers which is simple yet very efficient approach to discriminative learning \n",
    "    of linear classifiers under convex loss functions such as (linear) Support\n",
    "    Vector Machines and Logistic Regression\n",
    "    #### some type optomizer:#   https://keras.io/optimizers/#adadelta\n",
    "    '''\n",
    "    #optiz = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.1)\n",
    "    optiz = Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0) #https://keras.io/optimizers/#adadelta\n",
    "    \n",
    "    model.compile(optimizer=optiz,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # # X_train, y_train, X_val, y_val = train_test_split(X, y, test_size=0.1)\n",
    "    # model.fit(X, y, batch_size=32, epochs=15, validation_split=0.1)\n",
    "\n",
    "    data_gen = ImageDataGenerator()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = data_gen.flow_from_directory(train_path, (img_width, img_height), shuffle='False', batch_size=32)\n",
    "val_data_gen = data_gen.flow_from_directory(test_path, (img_width, img_height), shuffle='False', batch_size=32)\n",
    "model.summary()\n",
    "\n",
    "#model = load_model('../fine_tuning_dogcat_resnet50')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if do not train ~Skip this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(train_data_gen, steps_per_epoch=nb_train_samples, epochs=epochs, validation_data=val_data_gen, validation_steps=nb_validation_samples,  callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "from skimage.io import imread_collection, imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "filepath='../every.resn50.hdf5'\n",
    "img_width, img_height = 243, 243\n",
    "\n",
    "train_data_dir = '../dataset/training_set/smo'\n",
    "validation_data_dir = '../dataset/test_set/smo'\n",
    "\n",
    "nb_train_samples = 5106\n",
    "nb_validation_samples = 1355\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "## load moduld o\n",
    "\n",
    "model = load_model('../every.resn50.94096.hdf5')\n",
    "#copyfile('../every.resn50.hdf5', '../every.resn50.94096.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "\n",
    "################################################################################    \n",
    "# Import the required modules\n",
    "%pylab inline \n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Grab the input device, in this case the webcam\n",
    "# You can also give path to the video file\n",
    "vid = cv2.VideoCapture(\"../dataset/source/smorking.mp4\")\n",
    "\n",
    "# Put the code in try-except statements\n",
    "# Catch the keyboard exception and \n",
    "# release the camera device and \n",
    "# continue with the rest of code.\n",
    "#plt.figure(figsize = (10,10))\n",
    "#fig = plt.figure()\n",
    "#print (\"fig = \") \n",
    "#<Figure size 432x288 with 0 Axes>\n",
    "label_no_smorking = \"predict: no Smorking\"\n",
    "label_smorking = \"predict: Smorking!\"\n",
    "count = 0\n",
    "\n",
    "#'''\n",
    "try:\n",
    "    while(True):\n",
    "        #''' Capture frame-by-frame '''\n",
    "        ret, frame = vid.read()\n",
    "        \n",
    "        #''' with biger image size comes slower playing show!  '''\n",
    "        #plt.figure(1,figsize=(10,5))\n",
    "        \n",
    "        if not ret:\n",
    "            # Release the Video Device if ret is false\n",
    "            vid.release()\n",
    "            # Message to be displayed after releasing the device\n",
    "            print(\"Released Video Resource\")\n",
    "            break\n",
    "            \n",
    "        #''' Write image to folder'''\n",
    "        #img_jpg = np.asarray(frame)\n",
    "        #cv2.imwrite(\"../dataset/source/out/cyril_frame%d.jpg\" % count, img_jpg)\n",
    "        #count = count + 1\n",
    "        \n",
    "        #predict image here !\n",
    "        resize = cv2.resize(frame, (img_width, img_height)) \n",
    "        resize = np.asarray(resize)\n",
    "        test_image = image.img_to_array(resize)\n",
    "        inputarray = test_image[np.newaxis,...] # dimension added to fit input size\n",
    "        result =  model.predict(inputarray)\n",
    "        #print(result)\n",
    "        #print(\"Predicted=%s\", result)\n",
    "        ans = result[0][1]\n",
    "        \n",
    "        # Convert the image from OpenCV BGR format to matplotlib RGB format\n",
    "        # to display the image\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        if ans > 0.45: \n",
    "        \n",
    "            # put text into image \n",
    "            # https://blog.csdn.net/GAN_player/article/details/78155283\n",
    "            cv2.putText(frame, label_smorking, (30, 80),  cv2.FONT_HERSHEY_SIMPLEX,1.0, (255,0, 0), 2)\n",
    "            #cv2.line(影像, 開始座標, 結束座標, 顏色, 線條寬度)\n",
    "            cv2.line(frame, (0, 0), (432, 0),     (255,0,0),  12)\n",
    "            cv2.line(frame, (0, 0), (0, 350),     (255,0,0),  12)\n",
    "            cv2.line(frame, (440, 0),(440, 440),  (255,0,0),  12)\n",
    "            cv2.line(frame, (0, 330),(440, 330),(255,0,0),12)\n",
    "\n",
    "        else:\n",
    "             # put text into image \n",
    "            # https://blog.csdn.net/GAN_player/article/details/78155283\n",
    "            cv2.putText(frame, label_no_smorking, (30, 80),  cv2.FONT_HERSHEY_SIMPLEX,1.0, (255,255, 255), 2)\n",
    "            #cv2.line(影像, 開始座標, 結束座標, 顏色, 線條寬度)\n",
    "        \n",
    "        # Turn off the axis\n",
    "        #plt.axis('off')\n",
    "\n",
    "        # plt.figure(figsize=(8, 1),)\n",
    "        # Title of the window\n",
    "        plt.title(\"Detecting ..\")\n",
    "        \n",
    "        \n",
    "        # Display the frame\n",
    "        \n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        # Display the frame until new frame is available\n",
    "        clear_output(wait=True)\n",
    "                \n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    #print(\"Released Video Resource\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predicted Picture from video frame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "from scipy import misc\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from keras.preprocessing import image\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "\n",
    "\n",
    "video_data_dir = '../dataset/source/smorking.mp4'\n",
    "#-------------------------------------------------------------------\n",
    "vidcap = cv2.VideoCapture(video_data_dir)\n",
    "#-------------------------------------------------------------------\n",
    "video_fps= int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "print (\"CAP_PROP_FPS= \",video_fps)\n",
    "#-------------------------------------------------------------------\n",
    "#video_pos = int(vidcap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "#print (\"CAP_PROP_POS_MSEC= \",video_pos)\n",
    "#-------------------------------------------------------------------\n",
    "video_w = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print (\"CAP_PROP_FRAME_WIDTH= \",video_w)\n",
    "#-------------------------------------------------------------------\n",
    "video_h = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print (\"CAP_PROP_FRAME_HEIGHT= \",video_h)\n",
    "#-------------------------------------------------------------------\n",
    "video_total_frame = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print (\"video_total_frame (CAP_PROP_FRAME_COUNT) = \",video_total_frame)\n",
    "#-------------------------------------------------------------------\n",
    "video_total_tims=  video_total_frame / video_fps\n",
    "print (\"video_total_frame = \",video_total_tims)\n",
    "video_total_tims_msec = video_total_tims * 1000\n",
    "print (\"video_total_tims_msec = \",video_total_tims_msec)\n",
    "#-------------------------------------------------------------------\n",
    "#video_total_times = int(vidcap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "#print (\"CV_CAP_PROP_POS_MSEC = \",video_total_times)\n",
    "\n",
    "\n",
    "msec_count = 0\n",
    "\n",
    "while msec_count <= video_total_tims_msec:\n",
    "\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC, msec_count) \n",
    "    success,imagecv2 = vidcap.read()\n",
    "    resize = cv2.resize(imagecv2, (img_width, img_height)) \n",
    "    test_image = image.img_to_array(resize)\n",
    "    test_image_expand_dims = np.expand_dims(test_image, axis = 0)\n",
    "    result = model.predict(test_image_expand_dims)\n",
    "    ans = result[0][1]\n",
    "    #print(ans)\n",
    "    \n",
    "    #save image here\n",
    "    #img_jpg = np.asarray(resize)    \n",
    "    #cv2.imwrite(\"../dataset/tmp/frame%d.jpg\" % msec_count, img_jpg)\n",
    "  \n",
    "    if ans > 0.45 :\n",
    "        \n",
    "        #convert RGB of image for IPL\n",
    "        frame = cv2.cvtColor(resize, cv2.COLOR_BGR2RGB) ### for IPL.show!!!\n",
    "\n",
    "        print (\"smorking---------------\")\n",
    "        #plt.imshow(img)\n",
    "        im = PIL.Image.fromarray(frame)\n",
    "        bio = BytesIO()\n",
    "        im.save(bio, format='png')\n",
    "        display(Image(bio.getvalue(), format='png'))        \n",
    "    \n",
    "    else :\n",
    "        \n",
    "        print (\"no smorking here ---------------\")\n",
    "\n",
    "        #convert RGB of image for IPL\n",
    "        frame = cv2.cvtColor(resize, cv2.COLOR_BGR2RGB) ### for IPL.show!!!\n",
    "\n",
    "        print (\"no smorking---------------\")\n",
    "        #plt.imshow(img)\n",
    "        im = PIL.Image.fromarray(frame)\n",
    "        bio = BytesIO()\n",
    "        im.save(bio, format='png')\n",
    "        display(Image(bio.getvalue(), format='png'))  \n",
    "        \n",
    "        print (\"-------------------------------------------------\")\n",
    "\n",
    "    msec_count = msec_count + (2000)\n",
    "\n",
    "\n",
    "print ( \"done, counts are\", msec_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import * # imports everything, quick and dirty\n",
    "import moviepy.editor as mpy # Clean. Then use mpy.VideoClip, etc.\n",
    "from moviepy.editor import VideoFileClip # just import what you need\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.fx.resize import resize\n",
    "\n",
    "\n",
    "clip = VideoFileClip(\"../dataset/source/smorking.mp4\").rotate(0)\n",
    "print( clip.duration )\n",
    "clip.ipython_display(maxduration=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
