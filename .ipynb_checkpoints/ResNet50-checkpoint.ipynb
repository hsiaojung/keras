{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "from skimage.io import imread_collection, imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "filepath='../every.resn50.hdf5'\n",
    "img_width, img_height = 243, 243\n",
    "\n",
    "train_data_dir = '../dataset/training_set/smo'\n",
    "validation_data_dir = '../dataset/test_set/smo'\n",
    "\n",
    "nb_train_samples = 4521\n",
    "nb_validation_samples = 770\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    \n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', pooling='avg'\n",
    "                       ,input_tensor=Input((img_width, img_height, 3)))\n",
    "        \n",
    "    # - https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #x = Flatten()(base_model.output)\n",
    "    x = Dense(2, activation='softmax', name='fc2')(base_model.output) #加入神經元(隱藏層) 2,foftmax\n",
    " \n",
    "    model = Model(base_model.input, x)\n",
    "\n",
    "    # for tmp in zip([x.name for x in model.layers], range(len(model.layers))):\n",
    "    #     print(tmp)\n",
    "\n",
    "    for layer in model.layers[140:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # load data\n",
    "    # now_path = os.path.abspath(os.path.curdir)\n",
    "    # project_path, tmp = os.path.split(now_path)\n",
    "    # train_path = os.path.join(project_path, 'train')\n",
    "    #train_path = '/home/zhangzhe/pycharm/dogcat/train'\n",
    "    train_path ='../dataset/training_set/smo'\n",
    "    test_path = '../dataset/test_set/smo'\n",
    "\n",
    "    #n = 25000\n",
    "    # X = np.zeros((n, 224, 224, 3), dtype=np.uint8)\n",
    "    # y = np.zeros((n, 2), dtype=np.float32)\n",
    "    #\n",
    "    # for i in range(n//2):\n",
    "    #     X[i] = resize(imread(os.path.join(train_path, 'cat.%d.jpg' % i)), (224, 224, 3))\n",
    "    #     X[i+n//2] = resize(imread(os.path.join(train_path, 'dog.%d.jpg' % i)), (224, 224, 3))\n",
    "    #     if i % 1000 == 0:\n",
    "    #         print(i)\n",
    "    #\n",
    "    # y[:n//2] = np.array([1.0, 0.0])\n",
    "    # y[n//2:] = np.array([0.0, 1.0])\n",
    "    #\n",
    "    # # \n",
    "    #optiz = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.1)\n",
    "    optiz = Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    #\n",
    "    \n",
    "    model.compile(optimizer=optiz,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # # X_train, y_train, X_val, y_val = train_test_split(X, y, test_size=0.1)\n",
    "    # model.fit(X, y, batch_size=32, epochs=15, validation_split=0.1)\n",
    "\n",
    "    data_gen = ImageDataGenerator()\n",
    "    \n",
    "    train_data_gen = data_gen.flow_from_directory(train_path, (img_width, img_height), shuffle='False', batch_size=32)\n",
    "    val_data_gen = data_gen.flow_from_directory(test_path, (img_width, img_height), shuffle='False', batch_size=32)\n",
    "    \n",
    "    model.summary()\n",
    "    model = load_model('fine_tuning_dogcat_resnet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "model.fit_generator(train_data_gen, steps_per_epoch=nb_train_samples, epochs=epochs, validation_data=val_data_gen, validation_steps=nb_validation_samples,  callbacks=callbacks_list)\n",
    "\n",
    "#model.save('fine_tuning_dogcat_resnet502')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "%pylab inline \n",
    "import cv2\n",
    "from .display import clear_output\n",
    "\n",
    "\n",
    "# Grab the input device, in this case the webcam\n",
    "# You can also give path to the video file\n",
    "vid = cv2.VideoCapture(\"../dataset/source/smorking.mp4\")\n",
    "\n",
    "# Put the code in try-except statements\n",
    "# Catch the keyboard exception and \n",
    "# release the camera device and \n",
    "# continue with the rest of code.\n",
    "try:\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            # Release the Video Device if ret is false\n",
    "            vid.release()\n",
    "            # Message to be displayed after releasing the device\n",
    "            print(\"Released Video Resource\")\n",
    "            break\n",
    "        # Convert the image from OpenCV BGR format to matplotlib RGB format\n",
    "        # to display the image\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Turn off the axis\n",
    "        axis('off')\n",
    "        # Title of the window\n",
    "        title(\"Input Stream\")\n",
    "        # Display the frame\n",
    "        imshow(frame)\n",
    "        show()\n",
    "        # Display the frame until new frame is available\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    #print(\"Released Video Resource\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  https://zulko.github.io/moviepy/getting_started/efficient_moviepy.html\n",
    "\n",
    "from moviepy.editor import * # imports everything, quick and dirty\n",
    "import moviepy.editor as mpy # Clean. Then use mpy.VideoClip, etc.\n",
    "from moviepy.editor import VideoFileClip # just import what you need\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.fx.resize import resize\n",
    "\n",
    "clip = VideoFileClip(\"../dataset/source/smorking.mp4\").rotate(0)\n",
    "print( clip.duration )\n",
    "clip.ipython_display(maxduration=666)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "from skimage.io import imread_collection, imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "filepath='../every.resn50.hdf5'\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = '../dataset/training_set/smo'\n",
    "validation_data_dir = '../dataset/test_set/smo'\n",
    "\n",
    "nb_train_samples = 4521\n",
    "nb_validation_samples = 770\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', pooling='avg',\n",
    "                          input_tensor=Input((224, 224, 3)))\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # for tmp in zip([x.name for x in base_model.layers], range(len(base_model.layers))):\n",
    "    #     print(tmp)\n",
    "\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(2, activation='softmax', name='fc2')(base_model.output)\n",
    "\n",
    "    model = Model(base_model.input, x)\n",
    "\n",
    "    # for tmp in zip([x.name for x in model.layers], range(len(model.layers))):\n",
    "    #     print(tmp)\n",
    "\n",
    "    for layer in model.layers[140:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # load data\n",
    "    # now_path = os.path.abspath(os.path.curdir)\n",
    "    # project_path, tmp = os.path.split(now_path)\n",
    "    # train_path = os.path.join(project_path, 'train')\n",
    "    #train_path = '/home/zhangzhe/pycharm/dogcat/train'\n",
    "    train3_path ='../dataset/training_set/smo'\n",
    "    val3_path = '../dataset/test_set/smo'\n",
    "\n",
    "    #n = 25000\n",
    "    # X = np.zeros((n, 224, 224, 3), dtype=np.uint8)\n",
    "    # y = np.zeros((n, 2), dtype=np.float32)\n",
    "    #\n",
    "    # for i in range(n//2):\n",
    "    #     X[i] = resize(imread(os.path.join(train_path, 'cat.%d.jpg' % i)), (224, 224, 3))\n",
    "    #     X[i+n//2] = resize(imread(os.path.join(train_path, 'dog.%d.jpg' % i)), (224, 224, 3))\n",
    "    #     if i % 1000 == 0:\n",
    "    #         print(i)\n",
    "    #\n",
    "    # y[:n//2] = np.array([1.0, 0.0])\n",
    "    # y[n//2:] = np.array([0.0, 1.0])\n",
    "    #\n",
    "    # # \n",
    "    #optiz = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.1)\n",
    "    optiz = Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "    #\n",
    "    model.compile(optimizer=optiz,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # # X_train, y_train, X_val, y_val = train_test_split(X, y, test_size=0.1)\n",
    "    # model.fit(X, y, batch_size=32, epochs=15, validation_split=0.1)\n",
    "\n",
    "    data_gen = ImageDataGenerator()\n",
    "    train_data_gen = data_gen.flow_from_directory(train3_path, (224, 224), shuffle='False', batch_size=32)\n",
    "    val_data_gen = data_gen.flow_from_directory(val3_path, (224, 224), shuffle='False', batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "from skimage.io import imread_collection, imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "filepath='../every.resn50.hdf5'\n",
    "img_width, img_height = 243, 243\n",
    "\n",
    "train_data_dir = '../dataset/training_set/smo'\n",
    "validation_data_dir = '../dataset/test_set/smo'\n",
    "\n",
    "nb_train_samples = 4521\n",
    "nb_validation_samples = 770\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    \n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', pooling='avg'\n",
    "                       ,input_tensor=Input((img_width, img_height, 3)))\n",
    "        \n",
    "    # - https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #x = Flatten()(base_model.output)\n",
    "    x = Dense(2, activation='softmax', name='fc2')(base_model.output) #加入神經元(隱藏層) 2,foftmax\n",
    " \n",
    "    model = Model(base_model.input, x)\n",
    "\n",
    "    # for tmp in zip([x.name for x in model.layers], range(len(model.layers))):\n",
    "    #     print(tmp)\n",
    "\n",
    "    for layer in model.layers[140:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # load data\n",
    "    # now_path = os.path.abspath(os.path.curdir)\n",
    "    # project_path, tmp = os.path.split(now_path)\n",
    "    # train_path = os.path.join(project_path, 'train')\n",
    "    #train_path = '/home/zhangzhe/pycharm/dogcat/train'\n",
    "    train_path ='../dataset/training_set/smo'\n",
    "    test_path = '../dataset/test_set/smo'\n",
    "\n",
    "    #n = 25000\n",
    "    # X = np.zeros((n, 224, 224, 3), dtype=np.uint8)\n",
    "    # y = np.zeros((n, 2), dtype=np.float32)\n",
    "    #\n",
    "    # for i in range(n//2):\n",
    "    #     X[i] = resize(imread(os.path.join(train_path, 'cat.%d.jpg' % i)), (224, 224, 3))\n",
    "    #     X[i+n//2] = resize(imread(os.path.join(train_path, 'dog.%d.jpg' % i)), (224, 224, 3))\n",
    "    #     if i % 1000 == 0:\n",
    "    #         print(i)\n",
    "    #\n",
    "    # y[:n//2] = np.array([1.0, 0.0])\n",
    "    # y[n//2:] = np.array([0.0, 1.0])\n",
    "    #\n",
    "    # # \n",
    "    #optiz = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.1)\n",
    "    optiz = Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    #\n",
    "    \n",
    "    model.compile(optimizer=optiz,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # # X_train, y_train, X_val, y_val = train_test_split(X, y, test_size=0.1)\n",
    "    # model.fit(X, y, batch_size=32, epochs=15, validation_split=0.1)\n",
    "\n",
    "    data_gen = ImageDataGenerator()\n",
    "    \n",
    "    train_data_gen = data_gen.flow_from_directory(train_path, (img_width, img_height), shuffle='False', batch_size=32)\n",
    "    val_data_gen = data_gen.flow_from_directory(test_path, (img_width, img_height), shuffle='False', batch_size=32)\n",
    "    \n",
    "    model.summary()\n",
    "    model = load_model('../every.resn50.90130.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "  \n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_path = '../dataset/source/out/'\n",
    "    # [cat, dog]\n",
    "    # yiyi is 1 if the image is a dog, 0 if cat\n",
    "\n",
    "    #model = load_model('/home/zhangzhe/pycharm/dogcat/src/fine_tuning_dogcat_resnet50')\n",
    "    #print('model load finished')\n",
    "\n",
    "    files = os.listdir(test_path)\n",
    "\n",
    "    prediction = []\n",
    "    file_indexs = []\n",
    "    im_ind = 0\n",
    "    print('Start Prediction: ')\n",
    "    for file in files:\n",
    "        print(im_ind, file)\n",
    "        img_path = os.path.join(test_path, file)\n",
    "        img_pil = load_img(img_path, target_size=(img_width, img_height))\n",
    "        img = img_to_array(img_pil)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        result = model.predict(img)\n",
    "        file_name, suffix = file.split('.')\n",
    "        prediction.append(result[0][1])\n",
    "        file_indexs.append(file_name)\n",
    "        ans = result[0][1];\n",
    "        print('show ans= ', ans)\n",
    "       \n",
    "        if ans > 0.45:\n",
    "            \n",
    "            print (\"smorking----------smorking------smorking------------------\")\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            #cv2.imshow(winname='show the image',mat=img) \n",
    "            im = PIL.Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))  #OpenCV转换成PIL.Image格式\n",
    "            #plt.imshow(im)\n",
    "            bio = BytesIO()\n",
    "            im.save(bio, format='png')\n",
    "            display(Image(bio.getvalue(), format='jpg'))\n",
    "            print (\"-------------------------------------------------\")\n",
    "            \n",
    "        else:\n",
    "            '''\n",
    "            print (\"no no no smorking------------------------\")\n",
    "            img = cv2.imread(img_path)\n",
    "            #cv2.imshow(winname='show the image',mat=img) \n",
    "            im = PIL.Image.fromarray(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))  #OpenCV转换成PIL.Image格式\n",
    "            #plt.imshow(im)\n",
    "            bio = BytesIO()\n",
    "            im.save(bio, format='png')\n",
    "            display(Image(bio.getvalue(), format='jpg'))\n",
    "            print (\"-------------------------------------------------\")\n",
    "            '''\n",
    "        print('     ', result[0][1], file_name)\n",
    "        im_ind += 1\n",
    "        \n",
    "    print('Finish prediction. ')\n",
    "\n",
    "    #df = pd.DataFrame({'id':file_indexs, 'label':prediction})\n",
    "    #df.to_csv('pred2.csv', index=None)\n",
    "    #df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load image from video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "  \n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from IPython.display import display, Image\n",
    "\n",
    "################################################################################    \n",
    "# Import the required modules\n",
    "%pylab inline \n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Grab the input device, in this case the webcam\n",
    "# You can also give path to the video file\n",
    "vid = cv2.VideoCapture(\"../dataset/source/smorking.mp4\")\n",
    "\n",
    "# Put the code in try-except statements\n",
    "# Catch the keyboard exception and \n",
    "# release the camera device and \n",
    "# continue with the rest of code.\n",
    "#plt.figure(figsize = (10,10))\n",
    "#fig = plt.figure()\n",
    "#print (\"fig = \") \n",
    "#<Figure size 432x288 with 0 Axes>\n",
    "label_no_smorking = \"predict: no Smorking\"\n",
    "label_smorking = \"predict: Smorking!\"\n",
    "count = 0\n",
    "\n",
    "#'''\n",
    "try:\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = vid.read()\n",
    "        if not ret:\n",
    "            # Release the Video Device if ret is false\n",
    "            vid.release()\n",
    "            # Message to be displayed after releasing the device\n",
    "            print(\"Released Video Resource\")\n",
    "            break\n",
    "        #get image here\n",
    "        \n",
    "        #save image here\n",
    "        #img_jpg = np.asarray(frame)\n",
    "        #cv2.imwrite(\"../dataset/source/out/cyril_frame%d.jpg\" % count, img_jpg)\n",
    "        #count = count + 1\n",
    "    \n",
    "        #predict image here !\n",
    "\n",
    "        resize = cv2.resize(frame, (img_width, img_height)) \n",
    "        resize = np.asarray(resize)\n",
    "        test_image = image.img_to_array(resize)\n",
    "        inputarray = test_image[np.newaxis,...] # dimension added to fit input size\n",
    "        result =  model.predict(inputarray)\n",
    "        #print(result)\n",
    "        #print(\"Predicted=%s\", result)\n",
    "        ans = result[0][1]\n",
    "        \n",
    "        # Convert the image from OpenCV BGR format to matplotlib RGB format\n",
    "        # to display the image\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if ans > 0.8: \n",
    "        \n",
    "            # put text into image \n",
    "            # https://blog.csdn.net/GAN_player/article/details/78155283\n",
    "            cv2.putText(frame, label_smorking, (30, 60),  cv2.FONT_HERSHEY_SIMPLEX,0.9, (255,0, 0), 2)\n",
    "            #cv2.line(影像, 開始座標, 結束座標, 顏色, 線條寬度)\n",
    "            cv2.line(frame, (0, 0), (432, 0),     (255,0,0),  12)\n",
    "            cv2.line(frame, (0, 0), (0, 350),     (255,0,0),  12)\n",
    "            cv2.line(frame, (440, 0),(440, 440),  (255,0,0),  12)\n",
    "            cv2.line(frame, (0, 330),(440, 330),(255,0,0),12)\n",
    "\n",
    "        else:\n",
    "             # put text into image \n",
    "            # https://blog.csdn.net/GAN_player/article/details/78155283\n",
    "            cv2.putText(frame, label_no_smorking, (30, 60),  cv2.FONT_HERSHEY_SIMPLEX,0.9, (255,255, 255), 2)\n",
    "            #cv2.line(影像, 開始座標, 結束座標, 顏色, 線條寬度)\n",
    "        \n",
    "        # Turn off the axis\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Title of the window\n",
    "        plt.title(\"Input Stream\")\n",
    "        # Display the frame\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        # Display the frame until new frame is available\n",
    "        clear_output(wait=True)\n",
    "                \n",
    "except KeyboardInterrupt:\n",
    "    # Release the Video Device\n",
    "    vid.release()\n",
    "    # Message to be displayed after releasing the device\n",
    "    #print(\"Released Video Resource\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
